{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chapter 3 – Classification**\n",
    "\n",
    "_This notebook contains all the sample code and solutions to the exercises in chapter 3._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/03_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ageron/handson-ml2/blob/master/03_classification.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python ≥3.5 is required\n",
    "import sys\n",
    "assert sys.version_info >= (3, 5)\n",
    "\n",
    "# Is this notebook running on Colab or Kaggle?\n",
    "IS_COLAB = \"google.colab\" in sys.modules\n",
    "IS_KAGGLE = \"kaggle_secrets\" in sys.modules\n",
    "\n",
    "# Scikit-Learn ≥0.20 is required\n",
    "import sklearn\n",
    "assert sklearn.__version__ >= \"0.20\"\n",
    "\n",
    "# Common imports\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "CHAPTER_ID = \"classification\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "    if tight_layout:\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning:** since Scikit-Learn 0.24, `fetch_openml()` returns a Pandas `DataFrame` by default. To avoid this and keep the same code as in the book, we use `as_frame=False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "mnist.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = mnist[\"data\"], mnist[\"target\"]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_digit(data):\n",
    "    image = data.reshape(28, 28)\n",
    "    plt.imshow(image, cmap = mpl.cm.binary,\n",
    "               interpolation=\"nearest\")\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.astype(np.uint8)\n",
    "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_5 = (y_train == 5)\n",
    "y_test_5 = (y_test == 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_test_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit = X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclass Classification\n",
    "\n",
    "* Binary classifiers distinguish between two classes\n",
    "* Multiclass classifiers distinguish between more than two classes\n",
    "\n",
    "* Some algorithms are natively able to handle multiclass classification\n",
    "    * e.g., Logistic regression, Random Forest, naive Bayes)\n",
    "* Other algorithms are strictly binary classifiers\n",
    "    * However, we can multiple binary classifiers to handle multiclass classificaiton problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One-versus-the-rest (OvR)\n",
    "* For example, if we want to classify images of digits into 10 classes (0 to 9)\n",
    "* We could create 10 binary classifiers\n",
    "    * a 0-detector, a 1-detector, a 2-detector, ... up to a 9-detector\n",
    "    * Then, to classify an unseen image\n",
    "        * We could run it through each of our 10 classifiers\n",
    "        * And select the one that produced the highest decision score\n",
    "        * This is called one-versus-the-rest (also called one-versus-all)\n",
    "\n",
    "#### One-versus-one (OvO)\n",
    "* Alternatively, we could create binary classifiers for every pair of digits\n",
    "    * e.g., 0-1, 0-2, 0-3,... 0-9, 1-2, 1-3,... 1-9, 2-3...\n",
    "    * This is called the one-versus-one strategy\n",
    "    * For N classes, we would need N x (N-1)/2 classifiers\n",
    "    * So for MNIST with 10 classes, we would need 10 x 9/2 = 45 binary classifiers!\n",
    "    * To classify an image, we would have to run it through all 45 classifiers\n",
    "    * And see which one won with most duels\n",
    "\n",
    "* An advantage of OvO is that each classifier is only trained on part of the training set (the part for the two classes being considered by that classifier)\n",
    "\n",
    "* Some algorithms do not scale well with the size of the training set, so in some cases OvO may be preferred\n",
    "* However, for most binary classification problems, OvR is preferred\n",
    "\n",
    "#### Scikit-learn, OvR, and OvO\n",
    "* The good news is that scikit-learn will detect when you try to use a binary classification algorithm for a multiclass task\n",
    "* And it will automatically run OvR or OvO, depending on the algorithm\n",
    "\n",
    "\n",
    "For example, below we will create a Support Vector Machine classifier using sklearn.svm.SVC: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_clf = SVC(gamma=\"auto\", random_state=42)\n",
    "svm_clf.fit(X_train[:1000], y_train[:1000]) # y_train, not y_train_5\n",
    "svm_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, scikit-learn chose to use a OvO strategy:  it trained 45 binary classifiers, compared the scores, and selected the one that won the most duels.\n",
    "\n",
    "We can call the decision_function() to look at this.\n",
    "\n",
    "It returns 10 scores per instance (instead of just 1):  one score per class (it's the number of won duels plus or minus a small amount to break ties based on the binary classifier scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_digit_scores = svm_clf.decision_function([some_digit])\n",
    "some_digit_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax(some_digit_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we train a classifier, it stores a list of the classes in its .classes_ attribute.\n",
    "\n",
    "In this case, we are lucky that the class at index 5 is also the digit 5.\n",
    "\n",
    "Things will not always work out so nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf.classes_[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted, we could force scikit-learn to use a particular strategy using the `OneVsOneClassifier` or `OneVsRestClassifier` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "ovr_clf = OneVsRestClassifier(SVC(gamma=\"auto\", random_state=42))\n",
    "ovr_clf.fit(X_train[:1000], y_train[:1000])\n",
    "ovr_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If not specificed, scikit-learn will select the strategy\n",
    "\n",
    "Let's look what happens when we use a SGDClassifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)\n",
    "sgd_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ooops... it thought the 5 was a 3.  Oh well... our classifier is not perfect.\n",
    "\n",
    "In this example, scikit-learn trained 10 binary classifiers.\n",
    "\n",
    "The decision_function() now returns one value per class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_clf.decision_function([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output above, we can see that most of the scores are negative.\n",
    "\n",
    "However, the score for class 3 is 1823.\n",
    "\n",
    "Since this was the highest score, it was the predicted class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a more complete evaluatation of the classifier, we could use cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the following two cells may take close to 30 minutes to run, or more depending on your hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad!  Over 85% on all test folds.  A random classifier would get 10% accuracy.\n",
    "\n",
    "However, we can do better.\n",
    "\n",
    "For example, scaling the inputs will help:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))\n",
    "cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Analysis\n",
    "\n",
    "Once we have found a promising model, we can look for ways to improve it.\n",
    "\n",
    "One way to do this is to look at where the classifier is making errors.\n",
    "\n",
    "Our first step will be to look at the confusion matrix.\n",
    "\n",
    "Since we are now doing multiclass classification, each class could be classified as any of the classes, so we get an NxN matrix:\n",
    "\n",
    "(recall that the rows are the actual and the columns are predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)\n",
    "conf_mx = confusion_matrix(y_train, y_train_pred)\n",
    "conf_mx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matshow(conf_mx, cmap=plt.cm.gray)\n",
    "save_fig(\"confusion_matrix_plot\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the matrix and plots above are showing us raw numeric counts.\n",
    "\n",
    "These could be influenced by the number of that class in the dataset.\n",
    "\n",
    "For example, the 5s are a bit darker in the plot.  This could mean:\n",
    "* the classifier does not perform as well on 5s\n",
    "* there are not as many 5s in the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus on the errors\n",
    "\n",
    "Instead of looking at raw counts, we will divide each value by the number of images in the corresponding class.\n",
    "\n",
    "This will give us error rates instead of absolute numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_sums = conf_mx.sum(axis=1, keepdims=True)\n",
    "norm_conf_mx = conf_mx / row_sums"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The items on the main diagonal are siutations where the classifier got the predication correct.\n",
    "\n",
    "To help us focus on the errors, we will block out the main diagonal with zeros.\n",
    "\n",
    "And we can plot our error rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.fill_diagonal(norm_conf_mx, 0)\n",
    "plt.matshow(norm_conf_mx, cmap=plt.cm.gray)\n",
    "save_fig(\"confusion_matrix_errors_plot\", tight_layout=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see several interesting things from the plot above:\n",
    "* the 8s column is bright, meaning that many images get misclassified as 8s\n",
    "* however, the 8s row is fairly dark, so most actual 8s get correctly classified as 8s\n",
    "* 3s and 5s are often confused (in both directions)\n",
    "    * lighter grey boxes at 3-5 and 5-3\n",
    "    \n",
    "    \n",
    "These insights could help us think of ways to improve our classifier:\n",
    "* We could add more training data for images that are confused to be 8s\n",
    "* We could add new features to help distinguish 8s, 5s, and 3s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multilabel Classification\n",
    "\n",
    "Some classification problems may involve recognizing multiple things from one input.\n",
    "\n",
    "For example, we might want to know if Alice, Bob, and Charlie are in a picture.\n",
    "* Outputting [0,1,1] would indicate that Bob and Charlie are in the picture, but not Alice\n",
    "* Outputting [1,0,1] would indicate that Alice and Charlie are in the picture, but not Bob\n",
    "\n",
    "In the example below, we will look at a simple multilabel classifier.\n",
    "\n",
    "We will create `y_multilabel` which will contain two labels for each instance in our dataset.\n",
    "* the first label will indicate if the image contains a digit greater than 7\n",
    "* the second label will indicate if the image contains a digit that is an odd number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "y_train_large = (y_train >= 7)\n",
    "y_train_odd = (y_train % 2 == 1)\n",
    "y_multilabel = np.c_[y_train_large, y_train_odd]\n",
    "y_multilabel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we can train a KNeighborsClassifier on the training data with our multilabels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier()\n",
    "knn_clf.fit(X_train, y_multilabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precitions made with this classifier will now return two labels in the output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf.predict([some_digit])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many ways to evaluate a multilabel classifier.\n",
    "\n",
    "One approach is to compute the F<sub>1</sub> score for each individual label and then compute an average score across all labels.\n",
    "\n",
    "This assumes that all labels are equally important.\n",
    "\n",
    "Alternatively, we could use a weighted average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Warning**: the following cell may take a very long time (possibly hours depending on your hardware)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)\n",
    "f1_score(y_multilabel, y_train_knn_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "    \n",
    "corpus = [\n",
    "    'This is the first document.',\n",
    "    'This document is the second document.',\n",
    "    'And this is the third one.',\n",
    "    'Is this the first document?',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a feature vector where every word is a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(corpus)\n",
    "words = vectorizer.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(X.toarray(), columns=words)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdoc = vectorizer.transform(['one document is first and second'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(newdoc.toarray(), columns=words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3.1 -- Classifying movie reviews\n",
    "\n",
    "In this exercise, you will build a binary classifier to determine if movie reviews from the Internet Movie Database (IMDB) are positive or negative.\n",
    "\n",
    "We will use a dataset of 1000 movie reviews from IMDB.\n",
    "\n",
    "The dataset is in the text file:  ../data/imdb_labelled.txt\n",
    "\n",
    "It originally comes from: https://github.com/microsoft/ML-Server-Python-Samples/blob/master/microsoftml/202/data/sentiment_analysis/imdb_labelled.txt\n",
    "\n",
    "Each line in the file consists of:\n",
    "* the text of the review \n",
    "* a tab character (\\t)\n",
    "* a label of 0 (negative review) or 1 (positive review)\n",
    "* a newline character (\\n)\n",
    "\n",
    "For example:\n",
    "\n",
    "```A very, very, very slow-moving, aimless movie about a distressed, drifting young man.  \t0\n",
    "Saw the movie today and thought it was a good effort, good messages for kids.  \t1\n",
    "Not sure who was more lost - the flat characters or the audience, nearly half of whom walked out.  \t0\n",
    "Buy it, play it, enjoy it, love it.  \t1\n",
    "```\n",
    "\n",
    "Below are suggested steps for creating and evaluating your classifier.\n",
    "\n",
    "When you have finished your program, go to Canvas --> Assignments --> Exercise 3.1 and submit ONE file with your python code (e.g., copy and save the code you write in the cell below).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 0: a few suggested things to import\n",
    "import string\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "# Step 1: Read the file into a list where each list item is one instance (one line) from the file\n",
    "with open(\"../data/imdb_labelled.txt\") as infile:\n",
    "    lines = infile.read().split('\\n')\n",
    "\n",
    "# Step 2: For each line do steps (2a through 2e)\n",
    "\n",
    "    # Step 2a: split the line to get the review text and the label\n",
    "\n",
    "    \n",
    "    # Step 2b: clean up the review text by\n",
    "    #   converting all the characters to lower case\n",
    "    #   removing any characters that are not a-z or a space character\n",
    "    #   note: you may wish to use regular expressions for this (import re)\n",
    "\n",
    "    \n",
    "    # Step 2c: convert the label from a string to a number\n",
    "\n",
    "    \n",
    "    # Step 2d: append the cleaned review text to a list\n",
    "\n",
    "    \n",
    "    # Step 2e: append the label to another list\n",
    "\n",
    "    \n",
    "    \n",
    "# Step 3: Instantiate a CountVectorizer and use it to convert the cleaned review lines to vectors\n",
    "\n",
    "\n",
    "# Step 4: Divide the data into a testing and training sets\n",
    "\n",
    "\n",
    "# Step 5: Instantiate a SGDClassifier and train it on the training data\n",
    "\n",
    "\n",
    "# Step 6: Make up a new review text and see what the classifier predicts for it\n",
    "\n",
    "\n",
    "# Step 7: Use 10-fold cross-validation to evaluate the classifier accuracy\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nav_menu": {},
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
